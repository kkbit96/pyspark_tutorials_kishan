from pyspark.python.pyspark.shell import spark
from pyspark.sql import SparkSession
from datetime import datetime, date
from pyspark.sql.types import *
import pyspark.sql.functions as F
import os
import sys
import json
from uuid import uuid4
from pyspark.sql import Row
from pyspark.sql.functions import col



spark = SparkSession.builder.appName('Session1').getOrCreate()
data = [("James", "Wan", 24, "New York"), ("Ann", "Hathaway", 28, "Toronto")]
columns = ["firstname", "lastname", "age", "city"]
df23 = spark.createDataFrame(data, schema=columns)
df24 = df23.select(F.col("firstname"), F.col("age"))
df25 = df23.select(F.col("firstname"), F.col("lastname"), F.col("age"), F.col("city"),
                   F.concat(F.col("firstname"), F.lit(", "), F.col("lastname")).alias(
                       "fullname"))  # try using F.concat to add two columns
cols = ["firstname", "lastname", "age", "city"]
df26 = df23.select(*[col(col_name) for col_name in cols])
df26.show()







